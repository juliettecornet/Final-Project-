{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c4e065c-f086-45a3-8df7-7d20aa2be6ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sentiment Analysis of Taylor Swift's Albums\n",
    "\n",
    "## Part 1: Introduction \n",
    "\n",
    "#### As a comparative literature major, close-reader textual analysis is some thing I'm particularly interested in. Therefore, when we begun doing textual analysis via data science, I knew this was what I wanted to do my final project on. Considering Taylor Swift has recently been making a comeback, I thought it would intersting to look into her music and her persona which is where I got the inspiration for this project.\n",
    "\n",
    "#### Taylor swift is known for constantly re-inventing herself. Her ever-changing persona is known to be split up into different \"eras.\" While this is very apparent in the changes of her physial appearance and in her music videos and concert performances, I am curious to see if these shifts are identifiable from the lyrics in all her albums alone.Through data and textual analysis, I want to see if certain trends in her lyrics give us insight into the different changes she has undergone over the years. Therefore, through a combination of data science and textual analysis, is it possible to indenity different trends in Taylor Swift's lyrics throughout her albums?\n",
    "\n",
    "The dataset I will be using is from Github and has every lyric from every song form her first eight albums: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-09-29/taylor_swift_lyrics.csv ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d685d4e2-9650-4089-8c6b-512d364d3603",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 2: Methods\n",
    "\n",
    "I will begin by importing the data frame using pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30715b62-0f7d-4eea-b3cf-6f395ee621ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea26d7f-c057-49d8-af56-400f1ddff446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/taylor_swift_lyrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ea9b7c-a741-4ca5-a8cc-5e03d3369591",
   "metadata": {},
   "source": [
    "Here is the imported data frame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83b93b6a-228d-41c5-9f4c-d7d9b5e955d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Album</th>\n",
       "      <th>Title</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Tim McGraw</td>\n",
       "      <td>He said the way my blue eyes shinx\\nPut those ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Picture to Burn</td>\n",
       "      <td>State the obvious, I didn't get my perfect fan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Teardrops on my Guitar</td>\n",
       "      <td>Drew looks at me,\\nI fake a smile so he won't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>A Place in This World</td>\n",
       "      <td>I don't know what I want, so don't ask me\\n'Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Cold As You</td>\n",
       "      <td>You have a way of coming easily to me\\nAnd whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>folklore</td>\n",
       "      <td>mad woman</td>\n",
       "      <td>What did you think I'd say to that?\\nDoes a sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>folklore</td>\n",
       "      <td>epiphany</td>\n",
       "      <td>Keep your helmet\\nKeep your life, son\\nJust a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>folklore</td>\n",
       "      <td>betty</td>\n",
       "      <td>Betty, I won't make assumptions about why you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>folklore</td>\n",
       "      <td>peace</td>\n",
       "      <td>Our coming of age has come and gone\\nSuddenly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>folklore</td>\n",
       "      <td>hoax</td>\n",
       "      <td>My only one\\nMy smoking gun\\nMy eclipsed sun\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Artist           Album                   Title   \\\n",
       "0    Taylor Swift   Taylor Swift                Tim McGraw   \n",
       "1    Taylor Swift   Taylor Swift           Picture to Burn   \n",
       "2    Taylor Swift   Taylor Swift   Teardrops on my Guitar    \n",
       "3    Taylor Swift   Taylor Swift    A Place in This World    \n",
       "4    Taylor Swift   Taylor Swift              Cold As You    \n",
       "..             ...            ...                      ...   \n",
       "127  Taylor Swift       folklore                 mad woman   \n",
       "128  Taylor Swift       folklore                  epiphany   \n",
       "129  Taylor Swift       folklore                     betty   \n",
       "130  Taylor Swift       folklore                     peace   \n",
       "131  Taylor Swift       folklore                      hoax   \n",
       "\n",
       "                                                Lyrics  \n",
       "0    He said the way my blue eyes shinx\\nPut those ...  \n",
       "1    State the obvious, I didn't get my perfect fan...  \n",
       "2    Drew looks at me,\\nI fake a smile so he won't ...  \n",
       "3    I don't know what I want, so don't ask me\\n'Ca...  \n",
       "4    You have a way of coming easily to me\\nAnd whe...  \n",
       "..                                                 ...  \n",
       "127  What did you think I'd say to that?\\nDoes a sc...  \n",
       "128  Keep your helmet\\nKeep your life, son\\nJust a ...  \n",
       "129  Betty, I won't make assumptions about why you ...  \n",
       "130  Our coming of age has come and gone\\nSuddenly ...  \n",
       "131  My only one\\nMy smoking gun\\nMy eclipsed sun\\n...  \n",
       "\n",
       "[132 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5500908a-8d3a-4ad4-a00f-7abc3a8e9c43",
   "metadata": {},
   "source": [
    "As you can see, it is split up into 4 different columns: Artist, Album, Title, Lyrics. Since I want to be doing a textual analysis of how her lyrics have changed  between her albums, the two columns that are important to my research are the Album column and the Lyrics columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9430ebd2-90ac-4756-9fc3-329ae2f246d7",
   "metadata": {},
   "source": [
    "For my analysis, I want to seperate all the albums and add combine the lyrics from all songs under one album title to make to text analysis procress easier. Therefore, below I turn the lyrics into lists based on the album they correspond to. I do this using a for loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d5818dc-3b87-4069-ae67-3659983efffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "taylor_swift = []\n",
    "fearless = []\n",
    "speak_now = []\n",
    "red = []\n",
    "album_1989 = []\n",
    "reputation = []\n",
    "lover = []\n",
    "folklore = []\n",
    "\n",
    "num_rows = len(df)\n",
    "# print(num_rows)\n",
    "\n",
    "for i in range(num_rows):\n",
    "    if df.loc[i,\"Album\"] == \"Taylor Swift \":\n",
    "        taylor_swift.append(df.loc[i,\"Lyrics\"])\n",
    "    elif df.loc[i,\"Album\"] == \"Fearless\":\n",
    "        fearless.append(df.loc[i,\"Lyrics\"])\n",
    "    elif df.loc[i,\"Album\"] == \"Speak Now \": \n",
    "        speak_now.append(df.loc[i,\"Lyrics\"])\n",
    "    elif df.loc[i,\"Album\"] == \"Red\":\n",
    "        red.append(df.loc[i,\"Lyrics\"])\n",
    "    elif df.loc[i,\"Album\"] == \"1989\": \n",
    "        album_1989.append(df.loc[i,\"Lyrics\"])\n",
    "    elif df.loc[i,\"Album\"] == \"reputation\":\n",
    "        reputation.append(df.loc[i,\"Lyrics\"])\n",
    "    elif df.loc[i,\"Album\"] == \"Lover \":\n",
    "        lover.append(df.loc[i,\"Lyrics\"])\n",
    "    elif df.loc[i,\"Album\"] == \"folklore \":\n",
    "        folklore.append(df.loc[i,\"Lyrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd161c5-29db-4f91-907b-05c875d40b1c",
   "metadata": {},
   "source": [
    "Now that the lists have been made, the first thing I want to do is look at the most frequently used words throughout each album to see if we can begin indeifying differences. But first I need to clean up my data by tokenizing each list and removing the stopwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f310e546-10b7-498f-964d-0d665d1268d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "nltk.download('stopwords')\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8451c727-d3a2-427a-9d9e-4bc90b570ddb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#turning my album lyric lists into strings\n",
    "taylor_swift_album = \" \".join(taylor_swift)\n",
    "fearless_album = \" \".join(fearless)\n",
    "red_album = \" \".join(red)\n",
    "album_1989_album = \" \".join(album_1989)\n",
    "reputation_album = \" \".join(reputation)\n",
    "lover_album = \" \".join(lover)\n",
    "folklore_album = \" \".join(folklore)\n",
    "speak_now_album = \" \".join(speak_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9fe5a09b-f8c3-4881-9988-3072232e9274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tokenizing\n",
    "#taylor_swift\n",
    "ts_sentences = sent_tokenize(taylor_swift_album)\n",
    "ts_words = word_tokenize(taylor_swift_album.lower())\n",
    "#fearless\n",
    "f_sentences = sent_tokenize(fearless_album)\n",
    "f_words = word_tokenize(fearless_album.lower())\n",
    "#speaknow\n",
    "s_sentences = sent_tokenize(speak_now_album)\n",
    "s_words = word_tokenize(speak_now_album.lower())\n",
    "#red\n",
    "r_sentences = sent_tokenize(red_album)\n",
    "r_words = word_tokenize(red_album.lower())\n",
    "#1989\n",
    "nine_sentences = sent_tokenize(album_1989_album)\n",
    "nine_words = word_tokenize(album_1989_album.lower())\n",
    "#reputation\n",
    "rep_sentences = sent_tokenize(reputation_album)\n",
    "rep_words = word_tokenize(reputation_album.lower())\n",
    "#lover\n",
    "l_sentences = sent_tokenize(lover_album)\n",
    "l_words = word_tokenize(lover_album.lower())\n",
    "#folklore\n",
    "fo_sentences = sent_tokenize(folklore_album)\n",
    "fo_words = word_tokenize(folklore_album.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c036862-4d3e-412f-8555-b3869c60e97b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#removing stopwords\n",
    "extrastopwords = ['``', \"'s\", \"''\", '``',\"n't\", \"'m\", 'oh',\"'ll\",'mmm',\"'wo\",\"'re'\", 'ai', \"'re\",\"'ve\", 'na','wan','would','said', \"'cause\"]    \n",
    "myStopWords = list(punctuation) + stopwords.words('english') + extrastopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9eec0e7b-6c99-4d8f-881e-3afc8c3b718c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsNoStopWords = [w for w in ts_words if w not in myStopWords]\n",
    "fNoStopWords = [w for w in f_words if w not in myStopWords]\n",
    "sNoStopWords = [w for w in s_words if w not in myStopWords]\n",
    "rNoStopWords = [w for w in r_words if w not in myStopWords]\n",
    "nineNoStopWords = [w for w in nine_words if w not in myStopWords]\n",
    "repNoStopWords = [w for w in rep_words if w not in myStopWords]\n",
    "lNoStopWords = [w for w in l_words if w not in myStopWords]\n",
    "foNoStopWords = [w for w in fo_words if w not in myStopWords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10de67f1-26ce-4227-b3d9-4962520f6662",
   "metadata": {},
   "source": [
    "Now that I've cleaned up the lyrics I pulled from the data set by tokenizing sentences and words and removing the stopwords, I can begin to look at the most frequently used words per album to begin indentifying different trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b0efc-b079-4507-a61c-cc611331cba6",
   "metadata": {},
   "source": [
    "Let's start with her first album: Taylor Swift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "13699e3c-ba7f-4c70-b917-0a51ffc5c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_ts = FreqDist(tsNoStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e8b15cf-43d5-457d-a8fd-ab1ea6ba4399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'know': 35, 'think': 26, 'never': 25, 'back': 23, 'love': 20, 'see': 18, 'one': 17, 'like': 17, 'beautiful': 17, 'way': 15, ...})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9e0889c-32de-46b8-8fd5-eba4c9f622de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "know 35\n",
      "think 26\n",
      "never 25\n",
      "back 23\n",
      "love 20\n",
      "see 18\n",
      "one 17\n",
      "like 17\n",
      "beautiful 17\n",
      "way 15\n",
      "song 15\n",
      "baby 15\n",
      "time 14\n",
      "take 14\n",
      "hope 13\n",
      "still 13\n",
      "could 12\n",
      "let 12\n",
      "everything 12\n",
      "got 12\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(freq_ts, key=freq_ts.get, reverse=True)[:20]:\n",
    "    print(i,freq_ts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06c60cf-d919-48ce-b237-a78da1c80710",
   "metadata": {},
   "source": [
    "Now for Fearless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a3e35412-33cf-4494-8c7b-b44526b19f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_f = FreqDist(fNoStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "923e298d-8be5-4d36-a979-170a96cb9772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "know 72\n",
      "like 41\n",
      "come 41\n",
      "ca 33\n",
      "never 31\n",
      "say 30\n",
      "feel 27\n",
      "see 26\n",
      "time 25\n",
      "baby 25\n",
      "one 24\n",
      "back 24\n",
      "way 23\n",
      "love 23\n",
      "fall 22\n",
      "could 22\n",
      "got 20\n",
      "tell 20\n",
      "help 20\n",
      "night 18\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(freq_f, key=freq_f.get, reverse=True)[:20]:\n",
    "    print(i,freq_f[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb68880-cce7-4819-bf88-c40ab3f04e9f",
   "metadata": {},
   "source": [
    "SpeaK Now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e50de83c-9c7f-4cc8-bfb8-787b5e7e0265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "back 63\n",
      "like 58\n",
      "know 42\n",
      "come 39\n",
      "'d 37\n",
      "ever 35\n",
      "go 33\n",
      "never 32\n",
      "see 32\n",
      "say 30\n",
      "time 29\n",
      "love 23\n",
      "around 23\n",
      "away 22\n",
      "still 22\n",
      "mean 22\n",
      "mind 21\n",
      "ca 21\n",
      "could 20\n",
      "grow 20\n"
     ]
    }
   ],
   "source": [
    "freq_s = FreqDist(sNoStopWords)\n",
    "for i in sorted(freq_s, key=freq_s.get, reverse=True)[:20]:\n",
    "    print(i,freq_s[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd96bded-4695-4aef-abab-61ccd7b54d42",
   "metadata": {},
   "source": [
    "Red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c8dcc5aa-277b-4434-8e7b-f0d94bdbb2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like 92\n",
      "know 83\n",
      "time 66\n",
      "never 53\n",
      "red 46\n",
      "oh-oh 45\n",
      "back 43\n",
      "yeah 36\n",
      "ever 35\n",
      "one 33\n",
      "stay 32\n",
      "trouble 32\n",
      "last 32\n",
      "got 30\n",
      "asking 25\n",
      "home 25\n",
      "everybody 25\n",
      "love 24\n",
      "better 24\n",
      "tell 23\n"
     ]
    }
   ],
   "source": [
    "freq_r = FreqDist(rNoStopWords)\n",
    "for i in sorted(freq_r, key=freq_r.get, reverse=True)[:20]:\n",
    "    print(i,freq_r[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9432fb3-7d4d-485e-a4ee-b8f04f72e44c",
   "metadata": {},
   "source": [
    "1989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "05d080b2-0a76-46ef-a9b2-5042075538bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wish 85\n",
      "love 84\n",
      "shake 70\n",
      "yet 65\n",
      "got 55\n",
      "new 45\n",
      "back 44\n",
      "like 42\n",
      "baby 41\n",
      "never 39\n",
      "go 39\n",
      "woods 38\n",
      "clear 37\n",
      "know 36\n",
      "say 34\n",
      "could 33\n",
      "stay 32\n",
      "gon 31\n",
      "york 30\n",
      "welcome 29\n"
     ]
    }
   ],
   "source": [
    "freq_nine = FreqDist(nineNoStopWords)\n",
    "for i in sorted(freq_nine, key=freq_nine.get, reverse=True)[:20]:\n",
    "    print(i,freq_nine[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2420ed29-2d88-4f45-80e8-df28a468ad39",
   "metadata": {},
   "source": [
    "Reputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "71062314-59ec-4a2c-80f5-a5ea22cbacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_rep = FreqDist(repNoStopWords)\n",
    "for i in sorted(freq_rep, key=freq_rep.get, reverse=True)[:20]:\n",
    "    print(i,freq_rep[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1e026b-b4e5-4ac8-a665-8d9eff2026ea",
   "metadata": {},
   "source": [
    "Lover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "631aff50-be67-4a3e-91b3-e2beac1239df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like 67\n",
      "'d 53\n",
      "want 49\n",
      "love 44\n",
      "one 43\n",
      "never 43\n",
      "see 42\n",
      "daylight 40\n",
      "know 38\n",
      "get 32\n",
      "oh-oh 31\n",
      "right 28\n",
      "go 27\n",
      "man 27\n",
      "baby 26\n",
      "say 23\n",
      "street 23\n",
      "think 22\n",
      "could 21\n",
      "got 20\n"
     ]
    }
   ],
   "source": [
    "freq_l = FreqDist(lNoStopWords)\n",
    "for i in sorted(freq_l, key=freq_l.get, reverse=True)[:20]:\n",
    "    print(i,freq_l[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0566459c-4512-4a9f-8c67-cb75b3b0e63b",
   "metadata": {},
   "source": [
    "Folklore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "950d7caa-cfbe-4996-953b-b82837dffb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never 44\n",
      "know 42\n",
      "time 38\n",
      "like 38\n",
      "think 21\n",
      "one 19\n",
      "'d 19\n",
      "knew 18\n",
      "gave 17\n",
      "love 17\n",
      "around 16\n",
      "could 15\n",
      "see 15\n",
      "still 15\n",
      "back 13\n",
      "mad 13\n",
      "come 12\n",
      "seen 12\n",
      "give 12\n",
      "showed 11\n"
     ]
    }
   ],
   "source": [
    "freq_fo = FreqDist(foNoStopWords)\n",
    "for i in sorted(freq_fo, key=freq_fo.get, reverse=True)[:20]:\n",
    "    print(i,freq_fo[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe796a6-433c-441c-93cb-1ccf71c808ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
